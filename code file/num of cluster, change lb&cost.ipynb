{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3705dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from osgeo import ogr\n",
    "import pandas as pd\n",
    "import tifffile as tiff #needed for the tif data for perry county\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance_matrix\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import sys\n",
    "from shapely.geometry import Polygon, box, Point, LineString, MultiLineString\n",
    "import pickle\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import tifffile as tiff #needed for the tif data for perry county\n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "from shapely.ops import snap, split, nearest_points\n",
    "#from shapely.geometry import MultiPoint, LineString\n",
    "#from dbfread import DBF\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import math\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import os\n",
    "import csv\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6add4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance\n",
    "def haversinedist(lat1, lon1, lat2, lon2):\n",
    "    R = 6373.0\n",
    "    \n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    \n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    \n",
    "    distance = R * c\n",
    "    return distance #unit in km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad04712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "def readClusterFile(fileID):\n",
    "    file = np.genfromtxt(fileID, delimiter=\",\", skip_header = 1)\n",
    "    file = file[:,1:]\n",
    "    return file\n",
    "clusterfile = 'Centralized_elevcluster' + str(1) + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abea728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/yuelanzhu/Downloads/Research/my code file\")\n",
    "# read data\n",
    "def readClusterFile(fileID):\n",
    "    file = np.genfromtxt(fileID, delimiter=\",\", skip_header = 1)\n",
    "    file = file[:,1:]\n",
    "    return file\n",
    "clusterfile = 'Centralized_elevcluster' + str(1) + '.csv'\n",
    "building_coords = readClusterFile(clusterfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad349ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe parameters\n",
    "pipesize = [0.05, 0.06, 0.08, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6] #m\n",
    "pipesize_str, pipecost = gp.multidict({'0.05': 8.7, '0.06': 9.5, '0.08': 11, \\\n",
    "                                                   '0.1': 12.6, '0.15': 43.5,'0.2': 141, '0.25': 151, '0.3': 161, '0.35':230, '0.4': 246, '0.45':262, \n",
    "                                                   '0.5':292, '0.6':315}) #$/m\n",
    "excavation = 25\n",
    "bedding_cost_sq_ft = 6\n",
    "capital_cost_pump_station = 166000\n",
    "ps_flow_cost = 0.19 * (1/4.381E-8) #$/gpd to $/m3s-1\n",
    "ps_OM_cost = 175950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "221f5eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat MST\n",
    "\n",
    "graph = []\n",
    "mstree = []\n",
    "def createMSTnx(dataframe,n):\n",
    "    #only takes longitude and latitude from the cluster data, note we also have elevation and stuff there too\n",
    "    #coordinates = twoDcluster\n",
    "    cluster = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='ward')\n",
    "    cluster.fit_predict(building_coords[:,1:2])\n",
    "    # add cluster to dataframe\n",
    "    dataframe['cluster.labels_'] = cluster.labels_.tolist()\n",
    "    for k in range(n):\n",
    "        cluster_label = dataframe[dataframe['cluster.labels_'] == k]\n",
    "        cluster_label = cluster_label[['longitude','latitude']]\n",
    "        latlon = cluster_label.to_numpy()\n",
    "        nrows, ncols = latlon.shape\n",
    "        #creates graph\n",
    "        graph.append(nx.Graph())\n",
    "        weights = []\n",
    "        #distance in km as weight between each point in the graph\n",
    "        for i in range(nrows):\n",
    "            graph[k].add_node(i,pos=(latlon[i,0],latlon[i,1]))\n",
    "            for j in range(i+1,nrows):\n",
    "                dist = haversinedist(latlon[i,1], latlon[i,0], latlon[j,1], latlon[j,0])\n",
    "                weights.append(dist)\n",
    "                graph[k].add_edge(i,j, weight = dist)\n",
    "        #creates MST\n",
    "        mstree.append(nx.minimum_spanning_tree(graph[k]))\n",
    "    return mstree, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf66d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data to dataframe\n",
    "df = pd.DataFrame(building_coords,\n",
    "                  columns = ['longitude','latitude','elevation'])\n",
    "#createMSTnx(df,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd10942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_c_2(df, num_c, cluster_labels, pipesize, pipecost, water_demand, HLmax, excavation, bedding_cost_sq_ft, capital_cost_pump_station, ps_OM_cost):\n",
    "\n",
    "    # select highest and lowest nodes in cluster\n",
    "    tank = df.loc[df.groupby(['cluster.labels_'])['elevation'].idxmax()].reset_index(drop=True)\n",
    "    trem = df.loc[df.groupby(['cluster.labels_'])['elevation'].idxmin()].reset_index(drop=True)\n",
    "                      \n",
    "     # find label of tank node in cluster\n",
    "    tank_lon = str(tank[tank['cluster.labels_'] == cluster_labels][['longitude']].iat[0,0])\n",
    "    tank_lat = str(tank[tank['cluster.labels_'] == cluster_labels][['latitude']].iat[0,0])\n",
    "    global tank_node\n",
    "    for i in mstree[cluster_labels].nodes():\n",
    "        if str(mstree[cluster_labels].nodes[i]['pos'][0]) == tank_lon and str(mstree[cluster_labels].nodes[i]['pos'][1]) == tank_lat:\n",
    "            tank_node = i                  \n",
    "    #create flow direction dict\n",
    "    links = list(mstree[cluster_labels].edges)\n",
    "    flow_dir = {}\n",
    "    for i,j in links:\n",
    "        if len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=i)) < len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=j)):\n",
    "        # if node i is nearer to tank\n",
    "           flow_dir[i,j]=(i,j)\n",
    "        if len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=i)) > len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=j)):\n",
    "         # if node j is nearer to tank\n",
    "           flow_dir[i,j]=(j,i) \n",
    "    # find nodes for inflow and outflow\n",
    "    innode = {}\n",
    "    outnode = {}\n",
    "    for i,j in links:\n",
    "        if len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=i)) > len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=j)):\n",
    "           # if node j is nearer to tank\n",
    "            innode.setdefault(i, [])\n",
    "            innode[i].append(j)\n",
    "            outnode.setdefault(j, [])\n",
    "            outnode[j].append(i)\n",
    "        else:\n",
    "           # if node i is nearer to tank\n",
    "            innode.setdefault(j, [])\n",
    "            innode[j].append(i)\n",
    "            outnode.setdefault(i, [])\n",
    "            outnode[i].append(j)\n",
    "    for i in mstree[cluster_labels].nodes():\n",
    "        innode.setdefault(i,[])\n",
    "        outnode.setdefault(i, [])\n",
    "   # directed graph\n",
    "    mstree_dir = nx.DiGraph()\n",
    "    mstree_dir.add_nodes_from(mstree[cluster_labels])\n",
    "    mstree_dir.add_edges_from(flow_dir.values())\n",
    "    weights = {}\n",
    "    for i in list(mstree_dir.edges()):\n",
    "        weights[i] = None\n",
    "    for i,j in flow_dir:\n",
    "        if flow_dir[i,j]==(i,j):\n",
    "            weights[i,j]=mstree[cluster_labels].edges[i,j]['weight']\n",
    "        if flow_dir[i,j]==(j,i):\n",
    "            weights[j,i]=mstree[cluster_labels].edges[i,j]['weight']\n",
    "    nx.set_edge_attributes(mstree_dir, values = 1, name = 'weight')\n",
    "    nx.set_edge_attributes(mstree_dir, values = weights, name = 'weight')\n",
    "    # determine iterate order\n",
    "    walk = {}\n",
    "    for i,j in mstree_dir.edges():\n",
    "        walk[i,j] = len(nx.shortest_path(mstree_dir ,source=tank_node, target=j))\n",
    "    sorted_walk = dict(sorted(walk.items(), key=lambda item: item[1], reverse = True))\n",
    "    # pipe flow\n",
    "    pipe_flow = {}\n",
    "    for i,j in sorted_walk:\n",
    "        if len(outnode[j]) == 0:\n",
    "            pipe_flow[i,j] = 1.095E-5\n",
    "        else:\n",
    "            pipe_flow[i,j] = sum(pipe_flow[m,n] for m,n in sorted_walk if m == j) + 1.095E-5 #250 gpd to m3/s\n",
    "    # head loss at largest dia        \n",
    "    head_loss = {}\n",
    "    for i in list(mstree_dir.edges()):\n",
    "        head_loss[i] = None\n",
    "    for i,j in list(mstree_dir.edges()):\n",
    "        head_loss[i,j] = 10700*(pipe_flow[i,j]/140)**1.852*0.6*1000*mstree_dir[i][j][\"weight\"]\n",
    "    # flow, distance and head loss for each edge\n",
    "    edge_list = {}\n",
    "    for i,j in links:\n",
    "        if (i,j) == flow_dir[i,j]:\n",
    "            edge_list[i,j] =[pipe_flow[i,j],mstree[cluster_labels][i][j][\"weight\"], head_loss[i,j]]\n",
    "        else:\n",
    "            edge_list[j,i] =[pipe_flow[j,i],mstree[cluster_labels][i][j][\"weight\"], head_loss[j,i]]\n",
    "   #node elevation excavation in meters\n",
    "   #upper bound is arbritrary maximum depth assuming 1 foot or 0.3048 meters of cover beneath the surface is needed for the pipes\n",
    "   #a lower bound variable is created but not used. In future models might need to implement that depending on the site (digging too deep for excavation is not feasible for many projects)\n",
    "    cluster = df[df['cluster.labels_'] == cluster_labels]\n",
    "    cluster_elv = cluster[['elevation']]\n",
    "    elevation_ub = dict()\n",
    "    elevation_lb = dict()\n",
    "    for i in range(len(cluster_elv)):\n",
    "        GE=float(str(cluster_elv.values.tolist()[i])[1:-1])\n",
    "        elevation_ub[i] = GE - 0.3\n",
    "        elevation_lb[i] = GE - 10 #10\n",
    "    GE=[]\n",
    "    for i in range(len(cluster_elv)):\n",
    "        GE.append(float(str(cluster_elv.values.tolist()[i])[1:-1]))\n",
    "    #for i in range(mstree[cluster_labels].number_of_nodes()):\n",
    "        #elevation_ub[i] = cluster_elv.iloc[[0]] - 0.3048\n",
    "        #elevation_lb[i] = cluster_elv.iloc[[0]] - 30\n",
    "        \n",
    "    m = gp.Model('pipe and pump distribution')\n",
    "    m.Params.timeLimit = 12000\n",
    "   # binary variable indicating if at link ij pipe of diameter k is implemented\n",
    "    d = m.addVars(mstree_dir.edges(), pipesize, vtype = GRB.BINARY, name = \"diameter\")\n",
    "   #continuous variable representing the hydro loss in link ij.\n",
    "    HL = m.addVars(mstree_dir.edges(),lb = 0, vtype = GRB.CONTINUOUS, name = \"hydro loss\")\n",
    "    # hydro gradient\n",
    "    #J = m.addVars(mstree[cluster_labels].edges(),lb = 0, vtype = GRB.CONTINUOUS, name = \"hydro gradient\")\n",
    "   # binary variable indicating if at link ij the pump of type m is implemented.\n",
    "    p = m.addVars(mstree_dir.edges(), vtype = GRB.BINARY, name = \"PUMP\")\n",
    "   #continuous variable representing the pressure injected by the pump at link ij.\n",
    "    pr = m.addVars(mstree_dir.edges(),lb = 0, vtype = GRB.CONTINUOUS, name = \"PRESSURE BY PUMP\")\n",
    "   #pipe elevations at node i \n",
    "    e = m.addVars(mstree_dir.nodes(), lb = 0, vtype = GRB.CONTINUOUS, name = 'In Node Elevation')\n",
    "   #continuous variable representing the head pressure at node i\n",
    "    H = m.addVars(mstree_dir.nodes(),lb = 0, vtype = GRB.CONTINUOUS, name = \"HEAD PRESSURE\")\n",
    "    for i,j in mstree_dir.edges():\n",
    "#Hazen Williams equation, A = 10700, C=140, P472\n",
    "        #m.addConstr(J[i,j] == \n",
    "                #10700*(edge_list[i,j][0]/140)**1.852*gp.quicksum(d[i,j,k]/(k**4.8704) for k in pipesize)\n",
    "               #, \"Hydro loss\")\n",
    "        m.addConstr(HL[i,j] == 10700*(edge_list[i,j][0]/140)**1.852*gp.quicksum(d[i,j,k]/(k**4.8704) for k in pipesize)*1000*mstree_dir[i][j][\"weight\"])\n",
    "        m.addConstr(HL[i,j] <= HLmax)\n",
    "#only one pipe per edge\n",
    "        m.addConstr((d.sum(i, j, '*') == 1.0), \"single size chosen\")\n",
    "#only one pump per edge\n",
    "        m.addConstr((p.sum(i, j, '*') <= 1.0), \"single type chosen\")\n",
    "    \n",
    "#injected pressure pr[i,j] must be less than a huge number.\n",
    "        #m.addConstr(pr[i,j]<=p[i,j]*10**6)\n",
    "    \n",
    "    # injected pressure pr[i,j] must be less than the capacity of pump.\n",
    "        m.addConstr(pr[i,j] <= p[i,j]*100, \"pressure by pump less than 100 m \")\n",
    "    # energy requirement\n",
    "        m.addConstr(H[j] == H[i] - HL[i,j] + e[i] - e[j] + pr[i,j], \"Energy balance\")\n",
    "    \n",
    "        #if len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=i)) < len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=j)):\n",
    "        # if node i is nearer to tank        \n",
    "            #m.addConstr(H[j] == H[i] -HL[i,j] + e[i] - e[j] + pr[i,j], \"Energy balance\")\n",
    "        #if len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=i)) > len(nx.shortest_path(mstree[cluster_labels],source=tank_node, target=j)):\n",
    "        # if node j is nearer to tank        \n",
    "            #m.addConstr(H[i] == H[j] -HL[i,j] + e[j] - e[i] + pr[i,j], \"Energy balance\")\n",
    "# Velocity must be between 0.6 and 3 m/s to 30\n",
    "        m.addConstr((\n",
    "           edge_list[i,j][0] <= ((3.14/4)*gp.quicksum(d[i,j,k]*k**2 for k in pipesize)) * 3), \"Velocity Max Constr\"+ str([i,j]))\n",
    "        #m.addConstr((\n",
    "           #edge_list[i,j][0] >= ((3.14/4)*gp.quicksum(d[i,j,k]*k**2 for k in pipesize)) * 0.6), \"Velocity Min Constr\" + str([i,j]))  \n",
    "    for i in range(len(cluster_elv)):\n",
    "#pipe elevation must be betwenn lb and ub\n",
    "        m.addConstr(e[i] >= elevation_lb[i], \"PIPE ELV LB\")\n",
    "        m.addConstr(e[i] <= elevation_ub[i], \"PIPE ELV UB\")\n",
    "    \n",
    "        m.addConstr(H[i] >= 31.646232670592248, \"Min head pressure\") #45 psi, covert it to m\n",
    "        m.addConstr(H[i] <= 56.26, \"Max head pressure\") #80 psi, covert it to m   \n",
    "        \n",
    "        \n",
    "    #m.addConstr(H[tank_node] == 31.646232670592248)\n",
    "                      \n",
    "                      \n",
    "    # pipe cost \n",
    "    obj1 = gp.quicksum(1000 * mstree_dir[i][j][\"weight\"] * gp.quicksum(pipecost[str(k)] * d[i, j, k] \n",
    "                                                           for k in pipesize) for i,j in mstree_dir.edges())\n",
    "    \n",
    "    # Capital cost of pump stations\n",
    "    obj2 = gp.quicksum(p.sum(i, j) * (capital_cost_pump_station + ps_flow_cost*edge_list[i,j][0]) for i,j in mstree_dir.edges())\n",
    "    #Operation and maintenance costs\n",
    "    obj3 = gp.quicksum(p.sum(i, j)*ps_OM_cost for i, j in mstree_dir.edges())\n",
    "    # Excavation cost\n",
    "    obj4 = gp.quicksum((1 + gp.quicksum(d[i,j,k]*k for k in pipesize)) *1000* mstree_dir[i][j][\"weight\"] * bedding_cost_sq_ft + excavation * \\\n",
    "                               (1 + gp.quicksum(d[i,j,k]*k for k in pipesize)) *1000* mstree_dir[i][j][\"weight\"] * 0.5 * ((GE[i] - e[i]) + (GE[j] - e[j])) for i, j in mstree_dir.edges())\n",
    "\n",
    "    # Capital cost of pump stations\n",
    "    #obj2 = gp.quicksum(1000 * mstree_dir[i][j][\"weight\"] * gp.quicksum(pumpcost[pumptype.index(m)] * p[i, j, m] \n",
    "                                                           #for m in pumptype) for i,j in mstree_dir.edges()) #+penalty\n",
    "\n",
    "    #Operation and maintenance costs\n",
    "    #obj3 = gp.quicksum(p.sum(i, j)*ps_OM_cost for i, j in mstree_dir.edges())\n",
    "\n",
    "    obj = obj1+obj2+obj3#+obj4                  \n",
    "    m.setObjective(obj, GRB.MINIMIZE)\n",
    "    m.optimize()\n",
    "    \n",
    "    # record dia\n",
    "    #count = 0\n",
    "    #for i, j in mstree_dir.edges():\n",
    "        #for k in range(len(pipesize)):\n",
    "            #if m.getVars()[k+count].X == 1:\n",
    "                #edge_list[i,j].append(pipesize[k])\n",
    "        #count = count + len(pipesize)\n",
    "    #d = []\n",
    "    #for i,j in mstree_dir.edges():\n",
    "        #d.append(edge_list[i,j][3])\n",
    "    #edge_dia = {}\n",
    "    #count = 0\n",
    "    #for i,j in links:\n",
    "        #edge_dia[i,j]=d[count]\n",
    "        #count = count+1    \n",
    "    \n",
    "    #plot\n",
    "    #pos = nx.spring_layout(mstree[cluster_labels])\n",
    "\n",
    "    #nx.draw_networkx(mstree[cluster_labels], pos)\n",
    "\n",
    "    #nx.draw_networkx_labels(mstree[cluster_labels], pos, labels=edge_dia,label_pos=0.5, font_size=8)\n",
    "\n",
    "    #plt.show()\n",
    "    \n",
    "    #save the result\n",
    "    current_path = os.getcwd()\n",
    "    folder = current_path +'/num_c'+ str(num_c)\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    os.chdir(folder)\n",
    "    \n",
    "    modelname = str(cluster_labels) + \".csv\" \n",
    "        #m.write(modelname)\n",
    "    modelfile = open(modelname, \"w\")\n",
    "    #modelfile.write(\"pipecost\" + str(pipecost))\n",
    "    #modelfile.write('range: %g \\n' % bound)\n",
    "    modelfile.write('tank: %g \\n' % tank_node)\n",
    "    modelfile.write('number of nodes: %g \\n' % len(mstree[cluster_labels].nodes()))\n",
    "    modelfile.write('number of edges: %g \\n' % len(mstree[cluster_labels].edges()))\n",
    "    #modelfile.write('number of continuous variables: %g \\n' % (2*len(mstree[cluster_labels].edges()) + 2*len(mstree[cluster_labels].nodes()))\n",
    "    #modelfile.write('number of binary variables: %g \\n' % 2*len(mstree[cluster_labels].edges()))\n",
    "    modelfile.write('capital_cost_pump_station: %g \\n' % capital_cost_pump_station)\n",
    "    modelfile.write('ps_OM_cost: %g \\n' % ps_OM_cost)\n",
    "    modelfile.write('water_demand: %g \\n' % water_demand)\n",
    "    modelfile.write('Solution Value: %g \\n' % m.objVal)\n",
    "    modelfile.write('Solution Value 1: %g \\n' % obj1.getValue())\n",
    "    modelfile.write('Solution Value 2: %g \\n'% obj2.getValue())\n",
    "    modelfile.write('Solution Value 3: %g \\n'% obj3.getValue())\n",
    "    modelfile.write('Solution Value 4: %g \\n'% obj4.getValue())\n",
    "    #modelfile.write('Solution Value 3: %g \\n'% obj3.getValue())                  \n",
    "    for v in m.getVars():\n",
    "        modelfile.write('%s %g \\n' % (str(v.varName), v.x))\n",
    "    modelfile.close()\n",
    "    \n",
    "    diameter = { k : v.X for k,v in d.items() if v.X ==1}\n",
    "    diameter = list(diameter.keys())\n",
    "    v_check = {}\n",
    "    \n",
    "    #for i,j in links:\n",
    "        #if (i,j) == flow_dir[i,j]:\n",
    "            #for k in range(len(links)):\n",
    "                #if diameter[k][0] == i and diameter[k][1] == j:\n",
    "                    #v_check[i,j] = [diameter[k][2],edge_list[i,j][0], edge_list[i,j][0]/(3.14*(diameter[k][2]/2)**2)]\n",
    "        #else:\n",
    "            #for k in range(len(links)):\n",
    "                #if diameter[k][0] == j and diameter[k][1] == i:\n",
    "                    #v_check[j,i] = [diameter[k][2],edge_list[j,i][0], edge_list[j,i][0]/(3.14*(diameter[k][2]/2)**2)]\n",
    "    \n",
    "    return obj.getValue(), obj1.getValue(), obj2.getValue(), obj3.getValue(), obj4.getValue()\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bacbf4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2023-09-14\n",
      "Set parameter TimeLimit to value 12000\n",
      "Gurobi Optimizer version 9.5.0 build v9.5.0rc5 (mac64[rosetta2])\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 774 rows, 1262 columns and 3784 nonzeros\n",
      "Model fingerprint: 0x5a648366\n",
      "Variable types: 282 continuous, 980 integer (980 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-07, 1e+02]\n",
      "  Objective range  [2e+02, 3e+05]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e-05, 1e+05]\n",
      "Presolve removed 597 rows and 317 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 177 rows, 945 columns, 1830 nonzeros\n",
      "Variable types: 119 continuous, 826 integer (826 binary)\n",
      "Found heuristic solution: objective 1.681917e+07\n",
      "\n",
      "Root relaxation: objective 3.521920e+04, 177 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 35219.1987    0    4 1.6819e+07 35219.1987   100%     -    0s\n",
      "H    0     0                    378865.77949 35219.1987  90.7%     -    0s\n",
      "H    0     0                    35586.224530 35219.1987  1.03%     -    0s\n",
      "H    0     0                    35574.241606 35219.1987  1.00%     -    0s\n",
      "     0     0 35374.0049    0   10 35574.2416 35374.0049  0.56%     -    0s\n",
      "     0     0 35374.0049    0    2 35574.2416 35374.0049  0.56%     -    0s\n",
      "H    0     0                    35476.804580 35374.0049  0.29%     -    0s\n",
      "H    0     0                    35461.547540 35374.0049  0.25%     -    0s\n",
      "H    0     0                    35420.351305 35374.0049  0.13%     -    0s\n",
      "     0     0 35374.0049    0    8 35420.3513 35374.0049  0.13%     -    0s\n",
      "H    0     0                    35395.941387 35374.0049  0.06%     -    0s\n",
      "     0     0 35380.0231    0   11 35395.9414 35380.0231  0.04%     -    0s\n",
      "     0     0 35384.6044    0   13 35395.9414 35384.6044  0.03%     -    0s\n",
      "     0     0 35385.9821    0   13 35395.9414 35385.9821  0.03%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 5\n",
      "  Cover: 1\n",
      "  Implied bound: 3\n",
      "  MIR: 17\n",
      "  StrongCG: 1\n",
      "  GUB cover: 6\n",
      "\n",
      "Explored 1 nodes (243 simplex iterations) in 0.07 seconds (0.02 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 9: 35395.9 35420.4 35461.5 ... 1.68192e+07\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.539594138708e+04, best bound 3.539289603827e+04, gap 0.0086%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(35395.941387080275, 35395.941387080275, 0.0, 0.0, 774946.5709539168)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert data to dataframe\n",
    "df = pd.DataFrame(building_coords,\n",
    "                  columns = ['longitude','latitude','elevation'])\n",
    "g_mst = createMSTnx(df,10)\n",
    "os.chdir(\"/Users/yuelanzhu/Downloads/Research/my code file\")\n",
    "num_c_2(df, 10, 9, pipesize, pipecost, 1.095E-5, 1e+5, excavation, bedding_cost_sq_ft, capital_cost_pump_station, ps_OM_cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "py3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
